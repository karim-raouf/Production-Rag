# Production Ready RAG System

A FastAPI-based AI text generation API with RAG (Retrieval-Augmented Generation) capabilities, real-time web scraping, document ingestion, security guardrails, and multi-provider auth.

---

## âœ¨ Features

- **Text Generation** â€” AI-powered text generation with streaming support (SSE & WebSocket)
- **RAG Pipeline** â€” Retrieval-Augmented Generation using Qdrant vector database
- **Web Scraping** â€” Real-time URL content extraction and integration into prompts
- **Document Ingestion** â€” PDF upload and processing for knowledge base enrichment
- **Security Guardrails** â€” Dual-layer LLM-based safety system (input + output) with score-based classification
- **Conversation Management** â€” Persistent conversation history with PostgreSQL
- **Multi-Model Support** â€” Integration with VLLM and Ollama backends
- **JWT Auth** â€” Secure JWT-based auth with token revocation support
- **GitHub OAuth** â€” Sign in with GitHub via OAuth 2.0 with CSRF protection
- **Session Management** â€” Server-side session middleware for OAuth flows and token storage
- **Request Monitoring** â€” HTTP middleware that logs every request to CSV with timing and status
- **CORS Support** â€” Configurable Cross-Origin Resource Sharing middleware

---

## ğŸ›¡ï¸ Security Guardrails

The system implements a **dual-layer guardrail architecture** using a dedicated LLM classifier that runs independently from the main chat model.

### Input Guardrail

Analyzes user queries **before** they reach the chat model. Detects:
- Prompt injection & jailbreak attempts
- System prompt extraction attacks
- Code injection & shell command execution
- Social engineering & harmful content requests

Returns `True` (safe) or `False` (unsafe). Runs **concurrently** with URL/RAG content fetching via `asyncio.create_task` â€” if the guardrail rejects, pending fetch tasks are cancelled immediately.

### Output Guardrail

Analyzes the AI-generated response **after** generation, using a **score-based system** (1-10):

| Score | Severity   | Action                            |
| ----- | ---------- | --------------------------------- |
| 1-3   | Safe       | Allowed                           |
| 4-6   | Suspicious | Allowed (below default threshold) |
| 7-8   | Unsafe     | Blocked                           |
| 9-10  | Critical   | Blocked                           |

Checks for: leaked system instructions, harmful content, sensitive data exposure, bypassed safety, and manipulation.

- **Non-streaming endpoint** â€” Blocks unsafe responses and returns a safe static message. Original response is saved to DB for auditing.
- **Streaming endpoint** â€” Runs after the stream completes. If unsafe, sends `[RETRACTED]` event to the client.

### Fail-Open Design

Both guardrails are configured with `fail_open=True` by default â€” if the guardrail times out or errors, the request is **allowed** to proceed. This prevents guardrail failures from blocking the entire service.

---

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ main.py                         # FastAPI entry point, middleware, router wiring
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py                   # Application settings (Pydantic BaseSettings)
â”‚   â”œâ”€â”€ logging.py                  # Request logging to CSV via Loguru
â”‚   â”œâ”€â”€ ml.py                       # Global ML model store
â”‚   â””â”€â”€ database/
â”‚       â”œâ”€â”€ database.py             # AsyncEngine & session factory
â”‚       â”œâ”€â”€ models.py               # SQLAlchemy ORM models (User, Token, Conversation, Message)
â”‚       â”œâ”€â”€ dependencies.py         # Database session dependency
â”‚       â”œâ”€â”€ repositories/           # Data access layer (CRUD operations)
â”‚       â”‚   â”œâ”€â”€ users.py
â”‚       â”‚   â”œâ”€â”€ tokens.py
â”‚       â”‚   â”œâ”€â”€ conversations.py
â”‚       â”‚   â””â”€â”€ messages.py
â”‚       â”œâ”€â”€ services/               # Business logic layer
â”‚       â”‚   â”œâ”€â”€ users.py
â”‚       â”‚   â”œâ”€â”€ tokens.py
â”‚       â”‚   â”œâ”€â”€ conversations.py
â”‚       â”‚   â””â”€â”€ messages.py
â”‚       â”œâ”€â”€ schemas/                # Pydantic request/response models
â”‚       â”‚   â”œâ”€â”€ users.py
â”‚       â”‚   â”œâ”€â”€ tokens.py
â”‚       â”‚   â”œâ”€â”€ conversations.py
â”‚       â”‚   â””â”€â”€ messages.py
â”‚       â””â”€â”€ routers/                # CRUD API endpoints
â”‚           â”œâ”€â”€ conversations/
â”‚           â””â”€â”€ messages/
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ router.py               # /auth/* endpoints (register, login, logout)
â”‚   â”‚   â”œâ”€â”€ dependencies.py         # Auth header & current user dependencies
â”‚   â”‚   â”œâ”€â”€ exceptions.py           # UnauthenticatedException
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py             # AuthService (register, authenticate, logout)
â”‚   â”‚   â”‚   â””â”€â”€ password.py         # Password hashing utilities (bcrypt)
â”‚   â”‚   â””â”€â”€ oauth/
â”‚   â”‚       â”œâ”€â”€ router.py           # OAuth router aggregator
â”‚   â”‚       â”œâ”€â”€ config.py           # OAuth credentials from AppSettings
â”‚   â”‚       â”œâ”€â”€ github/
â”‚   â”‚       â”‚   â”œâ”€â”€ router.py       # /oauth/github/* endpoints (login, callback)
â”‚   â”‚       â”‚   â””â”€â”€ dependencies.py # CSRF check, token exchange, user info
â”‚   â”‚       â””â”€â”€ google/             # (Placeholder for Google OAuth)
â”‚   â”œâ”€â”€ text_generation/
â”‚   â”‚   â”œâ”€â”€ router.py               # API endpoints (POST, SSE, WebSocket)
â”‚   â”‚   â”œâ”€â”€ schemas.py              # Request/response schemas
â”‚   â”‚   â”œâ”€â”€ dependencies.py         # Annotated FastAPI deps (client, guardrails)
â”‚   â”‚   â”œâ”€â”€ guardrails/
â”‚   â”‚   â”‚   â”œâ”€â”€ schema.py           # InputGuardResponse & OutputGuardResponse
â”‚   â”‚   â”‚   â”œâ”€â”€ input_guardrail.py  # InputGuardrail class (True/False classification)
â”‚   â”‚   â”‚   â””â”€â”€ output_guardrail.py # OutputGuardrail class (1-10 score classification)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ generation_service.py  # VLLM-based generation
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama_cloud_service.py # Ollama chat client (invoke + streaming)
â”‚   â”‚   â”‚   â””â”€â”€ stream.py           # WebSocket connection manager
â”‚   â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py     # RAG content dependency
â”‚   â”‚   â”‚   â”œâ”€â”€ repository.py       # Qdrant vector store operations
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py          # RAG retrieval logic
â”‚   â”‚   â”‚   â”œâ”€â”€ extractor.py        # Embedding extraction
â”‚   â”‚   â”‚   â””â”€â”€ transform.py        # Text chunking & transformation
â”‚   â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”‚   â”œâ”€â”€ dependencies.py     # URL content dependency
â”‚   â”‚   â”‚   â””â”€â”€ service.py          # Web content extraction
â”‚   â”‚   â””â”€â”€ infrastructure/
â”‚   â”‚       â””â”€â”€ model_lifecycle.py   # Model loading & cleanup at startup/shutdown
â”‚   â”œâ”€â”€ document_ingestion/
â”‚   â”‚   â”œâ”€â”€ router.py               # /api/assets/documents/* endpoints
â”‚   â”‚   â”œâ”€â”€ schema.py               # Upload schemas
â”‚   â”‚   â”œâ”€â”€ service.py              # PDF processing & chunking
â”‚   â”‚   â””â”€â”€ dependencies.py         # File upload dependencies
â”‚   â””â”€â”€ image_generation/           # (Placeholder)
â””â”€â”€ pages/                          # Static HTML files
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.10+
- PostgreSQL database
- Qdrant vector database
- (Optional) VLLM or Ollama instance for LLM inference

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd generataion_webscraping_practice
   ```

2. **Create virtual environment**
   ```bash
   python -m venv .venv
   .venv\Scripts\activate  # Windows
   # source .venv/bin/activate  # Linux/Mac
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment variables**
   ```bash
   cp .env.example .env
   ```

   Edit `.env` with your configuration:
   ```env
   UPLOAD_CHUNK_SIZE=1048576    # 1MB
   RAG_CHUNK_SIZE=4000          # ~1k tokens
   EMBEDDING_SIZE=768

   QDRANT_HOST=localhost
   QDRANT_PORT=6333

   VLLM_API_KEY=your-vllm-api-key
   OLLAMA_API_KEY=your-ollama-api-key
   POSTGRES_URL=postgresql+asyncpg://user:password@localhost:5432/dbname

   # JWT Settings
   JWT_SECRET_KEY=your-super-secret-key-change-in-production
   JWT_ALGORITHM=HS256
   JWT_EXPIRES_IN_MINUTES=60

   # GitHub OAuth
   GITHUB_OAUTH_CLIENT_ID=your-github-client-id
   GITHUB_OAUTH_CLIENT_SECRET=your-github-client-secret
   ```

5. **Run database migrations**
   ```bash
   alembic upgrade head
   ```

6. **Start the server**
   ```bash
   uvicorn app.main:app --reload --port 8080
   ```

---

## ğŸ“š API Endpoints

### Auth (Public)
| Method | Endpoint         | Description                |
| ------ | ---------------- | -------------------------- |
| `POST` | `/auth/register` | Register a new user        |
| `POST` | `/auth/token`    | Login and get access token |
| `POST` | `/auth/logout`   | Logout and revoke token    |

### GitHub OAuth (Public)
| Method | Endpoint                 | Description                                    |
| ------ | ------------------------ | ---------------------------------------------- |
| `GET`  | `/oauth/github/login`    | Redirect to GitHub for authorization           |
| `GET`  | `/oauth/github/callback` | GitHub callback â€” exchanges code for JWT token |

### Health Check
| Method | Endpoint      | Description                |
| ------ | ------------- | -------------------------- |
| `GET`  | `/api/health` | Check API and model status |

### Text Generation (Protected)
| Method | Endpoint                                                     | Description                        |
| ------ | ------------------------------------------------------------ | ---------------------------------- |
| `POST` | `/api/text-generation/text-to-text/vllm`                     | Generate text via VLLM             |
| `POST` | `/api/text-generation/text-to-text/ollama/{conversation_id}` | Generate text via Ollama (guarded) |
| `GET`  | `/api/text-generation/stream/text-to-text/{conversation_id}` | Stream response via SSE (guarded)  |
| `WS`   | `/api/text-generation/ws/text-to-text`                       | WebSocket streaming                |

### Document Ingestion (Protected)
| Method | Endpoint                            | Description         |
| ------ | ----------------------------------- | ------------------- |
| `POST` | `/api/assets/documents/upload_file` | Upload PDF document |

### Conversations & Messages (Protected)
| Method     | Endpoint                  | Description               |
| ---------- | ------------------------- | ------------------------- |
| `GET/POST` | `/api/conversations/`     | List/Create conversations |
| `GET`      | `/api/conversations/{id}` | Get conversation by ID    |
| `GET/POST` | `/api/messages/`          | List/Create messages      |

---

## ğŸ” Auth

The API supports **two auth methods**: JWT Bearer Token and GitHub OAuth 2.0. All `/api/*` endpoints are protected.

### JWT Auth Flow

1. **Register** a new user:
   ```bash
   curl -X POST http://localhost:8080/auth/register \
     -H "Content-Type: application/json" \
     -d '{"username": "user", "email": "user@example.com", "password": "password"}'
   ```

2. **Login** to get access token:
   ```bash
   curl -X POST http://localhost:8080/auth/token \
     -H "Content-Type: application/x-www-form-urlencoded" \
     -d "username=user&password=password"
   ```

3. **Use token** for protected endpoints:
   ```bash
   curl http://localhost:8080/api/health \
     -H "Authorization: Bearer <access_token>"
   ```

4. **Logout** to revoke token:
   ```bash
   curl -X POST http://localhost:8080/auth/logout \
     -H "Authorization: Bearer <access_token>"
   ```

### GitHub OAuth Flow

1. Navigate to `http://localhost:8080/oauth/github/login`
2. User is redirected to GitHub for authorization
3. GitHub redirects back to `/oauth/github/callback` with an authorization code
4. The server exchanges the code for an access token, fetches user info, and creates/links the account
5. A JWT token is stored in the session and the user is redirected to `/`

> **Note:** GitHub OAuth requires a registered GitHub OAuth App. Set `GITHUB_OAUTH_CLIENT_ID` and `GITHUB_OAUTH_CLIENT_SECRET` in your `.env` file. The callback URL in your GitHub App should point to `http://localhost:8080/oauth/github/callback`.

---

## ğŸ”§ Configuration

| Variable                     | Description                        | Default     |
| ---------------------------- | ---------------------------------- | ----------- |
| `UPLOAD_CHUNK_SIZE`          | File upload chunk size in bytes    | `1048576`   |
| `RAG_CHUNK_SIZE`             | Text chunk size for RAG processing | `4000`      |
| `EMBEDDING_SIZE`             | Vector embedding dimensions        | `768`       |
| `QDRANT_HOST`                | Qdrant server hostname             | `localhost` |
| `QDRANT_PORT`                | Qdrant server port                 | `6333`      |
| `VLLM_API_KEY`               | VLLM API key                       | â€”           |
| `OLLAMA_API_KEY`             | Ollama API key                     | â€”           |
| `POSTGRES_URL`               | PostgreSQL async connection string | â€”           |
| `JWT_SECRET_KEY`             | Secret key for JWT token signing   | â€”           |
| `JWT_ALGORITHM`              | Algorithm for JWT signing          | `HS256`     |
| `JWT_EXPIRES_IN_MINUTES`     | Token expiration time in minutes   | `60`        |
| `GITHUB_OAUTH_CLIENT_ID`     | GitHub OAuth App client ID         | â€”           |
| `GITHUB_OAUTH_CLIENT_SECRET` | GitHub OAuth App client secret     | â€”           |

---

## ğŸ—„ï¸ Database Models

The application uses **SQLAlchemy 2.0** async ORM with **PostgreSQL** and **Alembic** for migrations.

| Model          | Table           | Key Fields                                                                                                               |
| -------------- | --------------- | ------------------------------------------------------------------------------------------------------------------------ |
| `User`         | `users`         | `id` (UUID), `github_id`, `email`, `username`, `hashed_password`, `role`, `is_active`                                    |
| `Token`        | `tokens`        | `id` (UUID), `user_id`, `expires_at`, `is_active`, `ip_address`                                                          |
| `Conversation` | `conversations` | `id`, `user_id`, `title`, `model_type`                                                                                   |
| `Message`      | `messages`      | `id`, `conversation_id`, `request_content`, `response_content`, `thinking_content`, `url_content`, `rag_content`, tokens |

All models include `created_at` and `updated_at` timestamps.

---

## ğŸ“ Project Structure

```
generataion_webscraping_practice/
â”œâ”€â”€ app/                    # Application source code
â”œâ”€â”€ alembic/                # Database migrations
â”œâ”€â”€ uploads/                # Uploaded documents (gitignored)
â”œâ”€â”€ dbstorage/              # Local database storage (gitignored)
â”œâ”€â”€ qdrant_storage/         # Qdrant data (gitignored)
â”œâ”€â”€ system_logs/            # Request logs (gitignored)
â”œâ”€â”€ .env.example            # Environment template
â”œâ”€â”€ alembic.ini             # Alembic configuration
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # This file
```

---

## ğŸ› ï¸ Development

### Running with Auto-reload
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8080
```

### Database Migrations
```bash
# Create new migration
alembic revision --autogenerate -m "description"

# Apply migrations
alembic upgrade head

# Rollback
alembic downgrade -1
```

### Dependency Injection Pattern

The text generation module uses **`Annotated` type aliases** for clean dependency injection:

```python
OllamaClientDep   = Annotated[OllamaCloudChatClient, Depends(get_ollama_client)]
InputGuardrailDep  = Annotated[InputGuardrail, Depends(get_input_guardrail)]
OutputGuardrailDep = Annotated[OutputGuardrail, Depends(get_output_guardrail)]
```

Each guardrail is a standalone class with its own `AsyncClient`, injected via FastAPI's `Depends()` â€” fully decoupled from the chat service.

### Middleware Stack

The application applies middleware in the following order:

1. **Session Middleware** â€” Stores OAuth state and access tokens in server-side sessions
2. **CORS Middleware** â€” Allows cross-origin requests (configured for all origins in development)
3. **Request Monitor** â€” Logs every HTTP request with timing, status code, and unique request ID

### Logging

The application uses **Loguru** for structured logging:
- Request logs are written to `system_logs/` as CSV files
- Application logs include request IDs for tracing
- Auth errors are logged at `ERROR` level for debugging
- Guardrail decisions are logged with classification details (score, threshold, allowed status)

---

## ğŸ“ License

This project is for educational and practice purposes.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
